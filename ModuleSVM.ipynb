{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "CLASS_NAMES=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'synth_lead', 'vocal']\n",
    "\n",
    "SOURCE_NAMES=['acoustic', 'electronic', 'synthetic']\n",
    "DATA_GROUPS=['test', 'valid', 'train']\n",
    "FEATURE_LIST=['y_harmonic', 'y_percussive', 'chroma_cens', 'mfcc','mel_spec', 'spec_contrast']\n",
    "\n",
    "def getDataset(dataGroup, source, target, other):#, instrument, source):\n",
    "    \n",
    "    new_dir='Dataset/nsynth-'+dataGroup+'/audio/'     #set the audio directory (test, train, etc)\n",
    "    dataframe_raw = pd.read_json(path_or_buf='Dataset/nsynth-'+dataGroup+'/examples.json', orient='index') #read all instruments from examples.json\n",
    "    dataframe_specific = dataframe_raw.loc[(dataframe_raw['instrument_family_str'] == target) | (dataframe_raw['instrument_family_str'] == other)]           #narrow down by family (strings, etc)\n",
    "    dataframe_specific = dataframe_specific.loc[dataframe_specific['instrument_source_str'] == source]     #narrow down by source (acoustic, etc)\n",
    "\n",
    "   \n",
    "    Y = dataframe_specific.instrument_family_str.replace(to_replace=[other, target], value=[0, 1])\n",
    "    filenames = dataframe_specific.index.tolist()     #get filenames from our dataframe, put into list\n",
    "    \n",
    "    dictionary = {}\n",
    "    for file in tqdm_notebook(filenames):             #for all files in filenames. Also,  tqdm is a loading bar\n",
    "       # print(new_dir)\n",
    "       # print(file)\n",
    "       # print('.wav')\n",
    "       # print(new_dir+file+'.wav')\n",
    "        features = feature_extract((new_dir+file+'.wav')) #specify directory, file, then add .wav. we will perform feature_extract with the file\n",
    "        dictionary[file] = features                       #make dictionary using file as rows - features as columns\n",
    "    featureDf = pd.DataFrame.from_dict(dictionary, orient='index', #turn into dataframe\n",
    "                                       columns=FEATURE_LIST)\n",
    "    featureFinal = pd.concat([dataframe_specific, featureDf], axis=1, sort=False)\n",
    "\n",
    "    featureFinal['targetValue'] = Y\n",
    "    return featureFinal #returns dataframe of features\n",
    "\n",
    "def feature_extract(file):\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    \n",
    "    hop_length = 512\n",
    "    \n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)    \n",
    "\n",
    "    #Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, \n",
    "                                                 fmax = 8000)\n",
    "    #Mel-Frequency Cepstral Coefficients (MFCC) features from the raw signal\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    \n",
    "    #Spectral Contrast\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    \n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    \n",
    "    y_harmonic = np.mean(y_harmonic)\n",
    "    y_percussive = np.mean(y_percussive)\n",
    "    mel_spec = np.mean(mel_spec)\n",
    "    mfcc = np.mean(mfcc, axis =1)\n",
    "    chroma_cens = np.mean(chroma_cens)\n",
    "    spec_contrast = np.mean(spec_contrast)\n",
    "    \n",
    "    return [y_harmonic, y_percussive, chroma_cens, mfcc, mel_spec, \n",
    "            spec_contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSVM():\n",
    "    dataGroup = DATA_GROUPS[0]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "    instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "    source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "    instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "    test = getDataset(dataGroup, source, instrumentTarget, instrumentOther)   #GETS DATAFRAME WITH FEATURES EXTRACTED BY AVERY\n",
    "\n",
    "    testX = test[FEATURE_LIST[0]].values.reshape(-1, 1)\n",
    "    testY = test['targetValue'].values.reshape(-1, 1)\n",
    "\n",
    "    print(test.targetValue)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataGroup = DATA_GROUPS[2]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "    instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "    source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "    instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "    train = getDataset(dataGroup, source, instrumentTarget, instrumentOther)\n",
    "    trainX = train[FEATURE_LIST[0]].array.reshape(-1, 1)\n",
    "    trainY = train['targetValue'].array.reshape(-1, 1)\n",
    "\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "\n",
    "    clf.fit(trainX, trainY)\n",
    "\n",
    "    prediction = clf.predict(testX)\n",
    "    accuracy = metrics.accuracy_score(testY, prediction)\n",
    "\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    return(prediction, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction,accuracy = runSVM()\n",
    "#dataGroup = DATA_GROUPS[0]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "#instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "#source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "#instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "#test = getDataset(dataGroup, source, instrumentTarget, instrumentOther)   #GETS DATAFRAME WITH FEATURES EXTRACTED BY AVERY\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataGroup = DATA_GROUPS[2]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "#instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "#source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "#instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "#train = getDataset(dataGroup, source, instrumentTarget, instrumentOther)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction,accuracy = runSVM()\n",
    "dataGroup = DATA_GROUPS[0]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "dataGroup = DATA_GROUPS[2]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.07166083e-05 -9.06469577e-05  1.77589028e-01 -1.81866417e+01\n",
      "   7.27748299e+00  2.59701879e+01]\n",
      " [ 5.75740842e-06 -3.56249757e-06  1.24513993e-01 -4.30868492e+01\n",
      "   5.40208340e-01  2.30403341e+01]\n",
      " [ 1.57342996e-07 -5.17807564e-07  1.95047449e-01 -3.19856873e+01\n",
      "   2.33462071e+00  2.79821943e+01]\n",
      " ...\n",
      " [ 5.67790400e-03  1.06937710e-04  2.15127750e-01 -2.26923027e+01\n",
      "   2.00748849e+00  3.02138538e+01]\n",
      " [-1.59582356e-07  8.30484339e-07  1.81291939e-01 -1.21194401e+01\n",
      "   6.78115034e+00  2.32143341e+01]\n",
      " [ 3.19001963e-08 -2.03483765e-07  1.78430171e-01 -3.47276802e+01\n",
      "   4.19028187e+00  2.61501757e+01]]\n",
      "[1 1 1 ... 0 1 1]\n",
      "(27458, 6)\n",
      "(27458,)\n",
      "[[-3.07166083e-05 -9.06469577e-05  1.77589028e-01 -1.81866417e+01\n",
      "   7.27748299e+00  2.59701879e+01]\n",
      " [ 5.75740842e-06 -3.56249757e-06  1.24513993e-01 -4.30868492e+01\n",
      "   5.40208340e-01  2.30403341e+01]\n",
      " [ 1.57342996e-07 -5.17807564e-07  1.95047449e-01 -3.19856873e+01\n",
      "   2.33462071e+00  2.79821943e+01]\n",
      " ...\n",
      " [ 5.67790400e-03  1.06937710e-04  2.15127750e-01 -2.26923027e+01\n",
      "   2.00748849e+00  3.02138538e+01]\n",
      " [-1.59582356e-07  8.30484339e-07  1.81291939e-01 -1.21194401e+01\n",
      "   6.78115034e+00  2.32143341e+01]\n",
      " [ 3.19001963e-08 -2.03483765e-07  1.78430171e-01 -3.47276802e+01\n",
      "   4.19028187e+00  2.61501757e+01]]\n",
      "[1 1 1 ... 0 1 1]\n",
      "(425, 6)\n",
      "[0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "Accuracy  y_harmonic :  0.8329411764705882\n"
     ]
    }
   ],
   "source": [
    "train = train.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "for x in range(1): \n",
    "    #print(FEATURE_LIST[x])\n",
    "    #testX = test.loc[:,[FEATURE_LIST[x]]]\n",
    "    #testX = test[FEATURE_LIST[x]].values\n",
    "    testX = test.drop(['targetValue'], axis=1)\n",
    "    testX = test[['y_harmonic','y_percussive', 'chroma_cens','mfcc', 'mel_spec', 'spec_contrast']]\n",
    "    testX = testX.to_numpy()\n",
    "    testY = test['targetValue'].values\n",
    "    #test[FEATURE_LIST[x]].values.reshape(-1, 1)\n",
    "    #testY = test['targetValue'].values.reshape(-1, 1)\n",
    "\n",
    "    #testX = testX.ravel()\n",
    "    #testY = testY.ravel()\n",
    "    \n",
    "    #trainX = train.loc[:,[FEATURE_LIST[x]]]\n",
    "    trainX = train[['y_harmonic', 'y_percussive','chroma_cens', 'mfcc', 'mel_spec', 'spec_contrast']]\n",
    "    trainX = trainX.to_numpy()\n",
    "    #trainX = train[FEATURE_LIST[x]].values\n",
    "    trainY = train['targetValue'].values\n",
    "    #trainX = train[FEATURE_LIST[x]].values.reshape(-1, 1)\n",
    "    #trainY = train['targetValue'].values.reshape(-1, 1)\n",
    "\n",
    "    #trainX = trainX.ravel()\n",
    "    #trainY = trainY.ravel()\n",
    "\n",
    "    #print(trainX.values)\n",
    "    \n",
    "    print(trainX)\n",
    "    print(trainY)\n",
    "    #bdf = datasets.load_breast_cancer()\n",
    "    \n",
    "    #print(bdf.data)\n",
    "    \n",
    "    #trainX, testX, trainY, testY = train_test_split(bdf.data, bdf.target, test_size=0.3,random_state=109)\n",
    "    \n",
    "    #print(trainX)\n",
    "    #print(trainY)\n",
    "    #print(testX)\n",
    "    #print(testY)\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')#kernel='rbf', C=100, gamma=10)\n",
    "\n",
    "    print(trainX.shape)\n",
    "    print(trainY.shape)\n",
    "    print(trainX)\n",
    "    print(trainY)\n",
    "    \n",
    "    print(testX.shape)\n",
    "    \n",
    "    clf.fit(trainX, trainY)\n",
    "\n",
    "    prediction = clf.predict(testX)\n",
    "    accuracy = metrics.accuracy_score(testY, prediction)\n",
    "    \n",
    "    print(prediction)\n",
    "\n",
    "    print(\"Accuracy \",FEATURE_LIST[x],\": \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
