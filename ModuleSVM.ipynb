{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "CLASS_NAMES=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'synth_lead', 'vocal']\n",
    "\n",
    "SOURCE_NAMES=['acoustic', 'electronic', 'synthetic']\n",
    "DATA_GROUPS=['test', 'valid', 'train']\n",
    "FEATURE_LIST=['y_harmonic', 'y_percussive', 'chroma_cens', 'mfcc','mel_spec', 'spec_contrast']\n",
    "\n",
    "def getDataset(dataGroup, source, target, other):#, instrument, source):\n",
    "    \n",
    "    new_dir='Dataset/nsynth-'+dataGroup+'/audio/'     #set the audio directory (test, train, etc)\n",
    "    dataframe_raw = pd.read_json(path_or_buf='Dataset/nsynth-'+dataGroup+'/examples.json', orient='index') #read all instruments from examples.json\n",
    "    dataframe_specific = dataframe_raw.loc[(dataframe_raw['instrument_family_str'] == target) | (dataframe_raw['instrument_family_str'] == other)]           #narrow down by family (strings, etc)\n",
    "    dataframe_specific = dataframe_specific.loc[dataframe_specific['instrument_source_str'] == source]     #narrow down by source (acoustic, etc)\n",
    "\n",
    "   \n",
    "    Y = dataframe_specific.instrument_family_str.replace(to_replace=[other, target], value=[0, 1])\n",
    "    filenames = dataframe_specific.index.tolist()     #get filenames from our dataframe, put into list\n",
    "    \n",
    "    dictionary = {}\n",
    "    for file in tqdm_notebook(filenames):             #for all files in filenames. Also,  tqdm is a loading bar\n",
    "       # print(new_dir)\n",
    "       # print(file)\n",
    "       # print('.wav')\n",
    "       # print(new_dir+file+'.wav')\n",
    "        features = feature_extract((new_dir+file+'.wav')) #specify directory, file, then add .wav. we will perform feature_extract with the file\n",
    "        dictionary[file] = features                       #make dictionary using file as rows - features as columns\n",
    "    featureDf = pd.DataFrame.from_dict(dictionary, orient='index', #turn into dataframe\n",
    "                                       columns=FEATURE_LIST)\n",
    "    featureFinal = pd.concat([dataframe_specific, featureDf], axis=1, sort=False)\n",
    "\n",
    "    featureFinal['targetValue'] = Y\n",
    "    return featureFinal #returns dataframe of features\n",
    "\n",
    "def feature_extract(file):\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    \n",
    "    hop_length = 512\n",
    "    \n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)    \n",
    "\n",
    "    #Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, \n",
    "                                                 fmax = 8000)\n",
    "    #Mel-Frequency Cepstral Coefficients (MFCC) features from the raw signal\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    \n",
    "    #Spectral Contrast\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    \n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    \n",
    "    y_harmonic = np.mean(y_harmonic)\n",
    "    y_percussive = np.mean(y_percussive)\n",
    "    mel_spec = np.mean(mel_spec, axis=1)\n",
    "    mfcc = np.mean(mfcc, axis =1)\n",
    "    chroma_cens = np.mean(chroma_cens, axis=1)\n",
    "    spec_contrast = np.mean(spec_contrast, axis=1)\n",
    "    \n",
    "    return [y_harmonic, y_percussive, chroma_cens, mfcc, mel_spec, \n",
    "            spec_contrast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSVM():\n",
    "    dataGroup = DATA_GROUPS[0]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "    instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "    source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "    instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "    test = getDataset(dataGroup, source, instrumentTarget, instrumentOther)   #GETS DATAFRAME WITH FEATURES EXTRACTED BY AVERY\n",
    "\n",
    "    testX = test[FEATURE_LIST[0]] \n",
    "    testY = test['targetValue']\n",
    "\n",
    "    print(test.targetValue)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataGroup = DATA_GROUPS[2]    #SET IF YOU WANT TEST, TRAIN, OR VALID (IF YOU HAVE IT)\n",
    "    instrumentTarget = CLASS_NAMES[8]   #SET THE INSTRUMENT YOU WANT\n",
    "    source = SOURCE_NAMES[0]      #SET ACOUSTIC, ELECTRONIC, SYNTHETIC\n",
    "    instrumentOther = CLASS_NAMES[4]\n",
    "\n",
    "    train = getDataset(dataGroup, source, instrumentTarget, instrumentOther)\n",
    "    trainX = train[FEATURE_LIST[0]] \n",
    "    trainY = train['targetValue']\n",
    "\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "\n",
    "    clf.fit(trainX, trainY)\n",
    "\n",
    "    prediction = clf.predict(testX)\n",
    "    accuracy = metrics.accuracy_score(testY, prediction)\n",
    "\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    return(prediction, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-cb7df813d005>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-cb7df813d005>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    feature =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a576b117514b42a17fb895ca7b8fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=425), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keyboard_acoustic_004-022-050    0\n",
      "keyboard_acoustic_004-025-100    0\n",
      "keyboard_acoustic_004-026-050    0\n",
      "keyboard_acoustic_004-026-100    0\n",
      "keyboard_acoustic_004-027-050    0\n",
      "                                ..\n",
      "string_acoustic_080-049-127      1\n",
      "string_acoustic_080-050-075      1\n",
      "string_acoustic_080-051-127      1\n",
      "string_acoustic_080-053-050      1\n",
      "string_acoustic_080-054-050      1\n",
      "Name: targetValue, Length: 425, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f2cdc8d0fa48a999903ee48d8872b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27458), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-31b89df1b469>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-7e3a03de185e>\u001b[0m in \u001b[0;36mrunSVM\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0minstrumentOther\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLASS_NAMES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstrumentTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstrumentOther\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFEATURE_LIST\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targetValue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-410e2f96bcb0>\u001b[0m in \u001b[0;36mgetDataset\u001b[1;34m(dataGroup, source, target, other)\u001b[0m\n\u001b[0;32m     36\u001b[0m        \u001b[1;31m# print('.wav')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m        \u001b[1;31m# print(new_dir+file+'.wav')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#specify directory, file, then add .wav. we will perform feature_extract with the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m                       \u001b[1;31m#make dictionary using file as rows - features as columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     featureDf = pd.DataFrame.from_dict(dictionary, orient='index', #turn into dataframe\n",
      "\u001b[1;32m<ipython-input-10-410e2f96bcb0>\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# Separate harmonics and percussives into two waveforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0my_harmonic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_percussive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m#Mel Spectrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\effects.py\u001b[0m in \u001b[0;36mhpss\u001b[1;34m(y, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# Decompose into harmonic and percussives\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mstft_harm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstft_perc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# Invert the STFTs.  Adjust length to match the input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\decompose.py\u001b[0m in \u001b[0;36mhpss\u001b[1;34m(S, kernel_size, power, mask, margin)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[0mperc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mperc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmedian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reflect'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0msplit_zeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmargin_harm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmargin_perc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mmedian_filter\u001b[1;34m(input, size, footprint, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \"\"\"\n\u001b[0;32m   1240\u001b[0m     return _rank_filter(input, 0, size, footprint, output, mode, cval,\n\u001b[1;32m-> 1241\u001b[1;33m                         origin, 'median')\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36m_rank_filter\u001b[1;34m(input, rank, size, footprint, output, mode, cval, origin, operation)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m         _nd_image.rank_filter(input, rank, footprint, output, mode, cval,\n\u001b[1;32m-> 1161\u001b[1;33m                               origins)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction,accuracy = runSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
