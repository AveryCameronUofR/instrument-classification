{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions declared\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\"\"\"\n",
    "Name: feature_extract\n",
    "Input: String name of file to analyze\n",
    "Returns: \n",
    "Array of:\n",
    "    y_harmonic\n",
    "    y_percussive \n",
    "    chroma_cens \n",
    "    mfcc\n",
    "    mel_spec\n",
    "    spec_contrast\n",
    "Note: \n",
    "    MFCC and Chroma_cens are arrays of 12\n",
    "    Mel_spec and spec_contrast are also closed.\n",
    "\"\"\"\n",
    "def feature_extract(file):\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    \n",
    "    hop_length = 512\n",
    "    \n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)    \n",
    "    \n",
    "    #Chroma Energy Normalized (CENS)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    \n",
    "    #Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=12, \n",
    "                                                 fmax = 8000)\n",
    "    #Mel-Frequency Cepstral Coefficients (MFCC) features from the raw signal\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    \n",
    "    #Spectral Contrast\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    \n",
    "    y_harmonic = np.mean(y_harmonic)\n",
    "    y_percussive = np.mean(y_percussive)\n",
    "    mel_spec = np.mean(mel_spec, axis=1)\n",
    "    mfcc = np.mean(mfcc, axis=1)\n",
    "    chroma_cens = np.mean(chroma_cens,axis=1)\n",
    "    spec_contrast = np.mean(spec_contrast, axis=1)\n",
    "    \n",
    "    return [y_harmonic, y_percussive, chroma_cens, mfcc, mel_spec, \n",
    "            spec_contrast]\n",
    "\n",
    "\"\"\"\n",
    "Name: get_dataset\n",
    "Input: \n",
    "    data_group: Train, valid, test set name\n",
    "    source: Acoustic, electronic, synthetic\n",
    "    class1: First instrument to classify\n",
    "    class2: second instrument to classify\n",
    "Returns: \n",
    "Array of:\n",
    "    y_harmonic\n",
    "    y_percussive \n",
    "    mel_spec\n",
    "    mfcc_0-12\n",
    "    chroma_0-12\n",
    "    spec_contrast\n",
    "\"\"\"\n",
    "def get_dataset(dataGroup, source, class1, class2):#, instrument, source):\n",
    "    \n",
    "    new_dir='Dataset/nsynth-'+dataGroup+'/audio/'     #set the audio directory (test, train, etc)\n",
    "    dataframe_raw = pd.read_json(path_or_buf='Dataset/nsynth-'+dataGroup+'/examples.json', orient='index') #read all instruments from examples.json\n",
    "    dataframe_specific = dataframe_raw.loc[(dataframe_raw['instrument_family_str'] == class2) | (dataframe_raw['instrument_family_str'] == class2)]           #narrow down by family (strings, etc)\n",
    "    dataframe_specific = dataframe_specific.loc[dataframe_specific['instrument_source_str'] == source]     #narrow down by source (acoustic, etc)\n",
    "\n",
    "   \n",
    "    Y_target_class = dataframe_specific.instrument_family_str.replace(to_replace=[class2, class1], value=[0, 1])\n",
    "    filenames = dataframe_specific.index.tolist()     #get filenames from our dataframe, put into list\n",
    "    \n",
    "    dictionary = {}\n",
    "    #Create the dictionary of files.\n",
    "    #Note: TQDM is a loading bar\n",
    "    for file in tqdm_notebook(filenames):           \n",
    "        features = feature_extract((new_dir+file+'.wav'))\n",
    "        dictionary[file] = features\n",
    "    \n",
    "    featureDf = pd.DataFrame.from_dict(dictionary, orient='index',\n",
    "                                       columns=['y_harmonic', 'y_percussive', 'chroma_cens', \n",
    "                                                'mfcc', 'mel_spec', 'spec_contrast'])\n",
    "    \n",
    "    #Take averages of each coefficient etc and create their own feature\n",
    "    mel_spec_data = pd.DataFrame(featureDf.mel_spec.values.tolist(), \n",
    "                                 index=featureDf.index)\n",
    "    mel_spec_data = mel_spec_data.add_prefix('Mel_Spec_')\n",
    "    \n",
    "    mfcc_data = pd.DataFrame(featureDf.mfcc.values.tolist(), \n",
    "                             index=featureDf.index)\n",
    "    mfcc_data = mfcc_data.add_prefix('MFCC_')\n",
    "    \n",
    "    chroma_data = pd.DataFrame(featureDf.chroma_cens.values.tolist(), \n",
    "                               index=featureDf.index)\n",
    "    chroma_data = chroma_data.add_prefix('Chroma_')\n",
    "    \n",
    "    spec_contrast_data = pd.DataFrame(featureDf.spec_contrast.values.tolist(), \n",
    "                                      index=featureDf.index)\n",
    "    spec_contrast_data = spec_contrast_data.add_prefix('Spec_Contrast_')\n",
    "    \n",
    "    #Drop the old feature columns\n",
    "    featureDf = featureDf.drop(\n",
    "        labels=['mel_spec', 'mfcc',\n",
    "                'chroma_cens', 'spec_contrast'],\n",
    "                                       axis=1)\n",
    "    #Add the extracted features\n",
    "    featureDf = pd.concat([featureDf, mel_spec_data, mfcc_data, \n",
    "                           chroma_data, spec_contrast_data],\n",
    "                         axis = 1, join='inner')\n",
    "    \n",
    "    qualities =  pd.DataFrame(dataframe_specific.qualities.values.tolist(), \n",
    "                         index = dataframe_specific.index)\n",
    "    qualities = qualities.add_prefix('NSynth_Quality_')\n",
    "    dataframe_specific = dataframe_specific.drop(labels=['instrument', 'instrument_family',\n",
    "                                                          'instrument_family_str', 'instrument_source',\n",
    "                                                          'instrument_source_str', 'instrument_str',\n",
    "                                                          'note', 'note_str', 'pitch',\n",
    "                                                          'qualities_str', 'sample_rate',\n",
    "                                                         'qualities'], axis=1)\n",
    "    dataframe_specific = dataframe_specific.drop(dataframe_specific.columns[0], axis=1)\n",
    "    featureFinal = pd.concat([dataframe_specific, featureDf, qualities], axis=1, sort=False)\n",
    "    featureFinal['target'] = Y_target_class\n",
    "    featureFinal.to_csv('./'+dataGroup+'.csv')\n",
    "    \n",
    "    #returns dataframe of features\n",
    "    return featureFinal \n",
    "\n",
    "\"\"\"\n",
    "Name: equalize_data\n",
    "Input: \n",
    "    class1: Data in class1\n",
    "    class2: Data in class2\n",
    "Returns: \n",
    "    equalized data from training\n",
    "\"\"\"\n",
    "def equalize_data(class1, class2):\n",
    "    class1_copy = class1\n",
    "    class2_copy = class2  \n",
    "    if (class1_copy['y_harmonic'].count() < class2_copy['y_harmonic'].count()):\n",
    "        while (class1_copy['y_harmonic'].count()<class2_copy['y_harmonic'].count()): \n",
    "            temp = [class1_copy, class1]\n",
    "            class2_copy = pd.concat(temp)\n",
    "        class2_copy = class2_copy[:class1_copy['y_harmonic'].count()]\n",
    "    else:\n",
    "        while (class2_copy['y_harmonic'].count()<class1_copy['y_harmonic'].count()):\n",
    "            temp = [class2_copy, class2]\n",
    "            class2_copy = pd.concat(temp)\n",
    "        class2_copy = class2_copy[:class1_copy['y_harmonic'].count()]\n",
    "    return (pd.concat([class1_copy, class2_copy]))\n",
    "\n",
    "def count_errors(predictions):\n",
    "    count = 0;\n",
    "    for pred in predictions:\n",
    "        if (pred[0] != pred[1]):\n",
    "            count += 1\n",
    "    return count;\n",
    "\n",
    "print('functions declared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\ipykernel_launcher.py:91: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe449d2de0c64c088c1384bcb0ff1c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-a0d4b60ebda7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mDATA_GROUPS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# get string members from dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acoustic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keyboard'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# get string members from dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acoustic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keyboard'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-d3be6aa50392>\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(dataGroup, source, class1, class2)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mfeatureFinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe_specific\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqualities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mfeatureFinal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_target_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mfeatureFinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdataGroup\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;31m#returns dataframe of features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './test.csv'"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'synth_lead', 'vocal']\n",
    "\n",
    "SOURCE_NAMES=['acoustic', 'electronic', 'synthetic']\n",
    "DATA_GROUPS=['test', 'valid', 'train']\n",
    "# get string members from dataset\n",
    "df_test = get_dataset('test', 'acoustic', 'keyboard','string')\n",
    "# get string members from dataset\n",
    "df_valid = get_dataset('valid', 'acoustic', 'keyboard','string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the datasets\n",
    "#(string_df_test, keyboard_df_test) = equalize_data(string_df_test, keyboard_df_test)\n",
    "# adding targets to dataframes\n",
    "#string_df_test['target'] = 0\n",
    "#keyboard_df_test['target'] = 1\n",
    "\n",
    "input_df_test = equalize_data(df_test[df_test['target'] == 0], df_test[df_test['target'] == 0])\n",
    "input_df_valid = equalize_data(df_valid[df_valid['target'] == 0], df_valid[df_valid['target'] == 0])\n",
    "\n",
    "\n",
    "# (string_df_valid, keyboard_df_valid) = equalize_data(string_df_valid, keyboard_df_valid)\n",
    "# string_df_valid['target'] = 0\n",
    "# keyboard_df_valid['target'] = 1\n",
    "# input_df_valid = pd.concat([string_df_valid, keyboard_df_valid])\n",
    "\n",
    "\n",
    "# # randomize datasets\n",
    "input_df_test = input_df_test.sample(frac=1).reset_index(drop=True)\n",
    "input_df_valid = input_df_valid.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# # encoding target as 0 for keyboard, 1 for string\n",
    "y_test = input_df_test['target']\n",
    "x_test = input_df_test.drop(labels=['target', ], axis=1)\n",
    "\n",
    "\n",
    "# # encoding target as 0 for keyboard, 1 for string\n",
    "y_valid = input_df_valid['target']\n",
    "x_valid = input_df_valid.drop(labels=['target'], axis=1)\n",
    "\n",
    "data_length_test = len(x_test)\n",
    "data_length_valid = len(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_decision_tree(max_depth):\n",
    "    # hyperparameters\n",
    "    # max_depth of 4 seems to work well for training with validation set\n",
    "\n",
    "    # create a scikit-learn tree based on validation set\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "    clf = clf.fit(x_valid, y_valid)\n",
    "\n",
    "    # make predictions\n",
    "    predictions_test = np.vstack((y_test, clf.predict(x_test).tolist())).T\n",
    "    predictions_valid = np.vstack((y_valid, clf.predict(x_valid).tolist())).T\n",
    "\n",
    "    num_errors_test = count_errors(predictions_test)\n",
    "    num_errors_valid = count_errors(predictions_valid)\n",
    "\n",
    "    # calculating valid and test error to two decimal places\n",
    "    validErrorPercentage = round(num_errors_valid / data_length_valid * 100, 2);\n",
    "    testErrorPercentage = round(num_errors_test / data_length_test * 100, 2)\n",
    "\n",
    "    errorLabels = ('Validation Set Error', 'Test Set Error')\n",
    "    plt.figure(0)\n",
    "    plt.title(\"Error in Validation vs Test\")\n",
    "    plt.ylabel(\"Error (%)\")\n",
    "    plt.bar('Valid', validErrorPercentage)\n",
    "    plt.bar('Test', testErrorPercentage)\n",
    "\n",
    "    print('Validation set error percentage: ', validErrorPercentage)\n",
    "    print('Test set error percentage: ', testErrorPercentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set error percentage:  0.0\n",
      "Test set error percentage:  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit a tree to our data and plot error\n",
    "simple_decision_tree(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(estimators):\n",
    "    classifier = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=estimators\n",
    "    )\n",
    "    classifier.fit(x_valid, y_valid)\n",
    "    predictions_test = classifier.predict(x_test)\n",
    "    results_test = confusion_matrix(y_test, predictions_test)\n",
    "    predictions_valid = classifier.predict(x_valid)\n",
    "    results_valid = confusion_matrix(y_valid, predictions_valid)\n",
    "    num_errors_test = results_test[0][1] + results_test[1][0]\n",
    "    num_errors_valid = results_valid[0][1] + results_valid[1][0]\n",
    "    \n",
    "    # calculating valid and test error to two decimal places\n",
    "    data_length_test = len(predictions_test)\n",
    "    data_length_valid = len(predictions_valid)\n",
    "    validErrorPercentage = round(num_errors_valid / data_length_valid * 100, 2);\n",
    "    testErrorPercentage = round(num_errors_test / data_length_test * 100, 2)\n",
    "\n",
    "    errorLabels = ('Validation Set Error', 'Test Set Error')\n",
    "    plt.figure(0)\n",
    "    plt.title(\"Error in Validation vs Test\")\n",
    "    plt.ylabel(\"Error (%)\")\n",
    "    plt.bar('Valid', validErrorPercentage)\n",
    "    plt.bar('Test', testErrorPercentage)\n",
    "\n",
    "    print('Validation set error percentage: ', validErrorPercentage)\n",
    "    print('Test set error percentage: ', testErrorPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[612]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-a442d6b7544c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mada_boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-e7f285f08dd2>\u001b[0m in \u001b[0;36mada_boost\u001b[1;34m(estimators)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mresults_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mnum_errors_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mnum_errors_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "ada_boost(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
